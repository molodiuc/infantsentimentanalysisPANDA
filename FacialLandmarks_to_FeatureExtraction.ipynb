{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FacialLandmarks_to_FeatureExtraction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sofiyasofie/infantsentimentanalysisPANDA/blob/dev/FacialLandmarks_to_FeatureExtraction.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "JOUemxElhhFK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np  \n",
        "import cv2  \n",
        "import dlib  \n",
        "   \n",
        "image_path = \"/Users/sofielysenko/Desktop/Images/infant_2.jpg\"  \n",
        "cascade_path = \"/anaconda3/pkgs/libopencv-3.4.1-h14a57ad_3/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml\"  \n",
        "predictor_path= \"/Users/sofielysenko/Documents/shape_predictor_68_face_landmarks.dat\"  \n",
        "   \n",
        "JAWLINE_POINTS = list(range(0, 17))  \n",
        "RIGHT_EYEBROW_POINTS = list(range(17, 22))  \n",
        "LEFT_EYEBROW_POINTS = list(range(22, 27))  \n",
        "NOSE_POINTS = list(range(27, 36))  \n",
        "RIGHT_EYE_POINTS = list(range(36, 42))  \n",
        "LEFT_EYE_POINTS = list(range(42, 48))  \n",
        "MOUTH_OUTLINE_POINTS = list(range(48, 61))  \n",
        "MOUTH_INNER_POINTS = list(range(61, 68)) \n",
        "\n",
        " # Create the haar cascade  \n",
        "faceCascade = cv2.CascadeClassifier(cascade_path)  \n",
        "   \n",
        " # create the landmark predictor  \n",
        "predictor = dlib.shape_predictor(predictor_path)  \n",
        "   \n",
        " # Read the image  \n",
        "image = cv2.imread(image_path)  \n",
        " # convert the image to grayscale  \n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  \n",
        "   \n",
        " # Detect faces in the image  \n",
        "faces = faceCascade.detectMultiScale(\n",
        "        gray,\n",
        "        scaleFactor=1.1,\n",
        "        minNeighbors=5,\n",
        "        minSize=(30, 30),\n",
        "        flags=cv2.CASCADE_SCALE_IMAGE\n",
        "    )\n",
        "   \n",
        "print(\"Found {0} faces!\".format(len(faces)))  \n",
        "   \n",
        "# Draw a rectangle around the faces  \n",
        "for (x, y, w, h) in faces:  \n",
        "  cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)  \n",
        "   \n",
        " # Converting the OpenCV rectangle coordinates to Dlib rectangle  \n",
        "dlib_rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))  \n",
        "print (dlib_rect) \n",
        "   \n",
        "detected_landmarks = predictor(image, dlib_rect).parts()  \n",
        "   \n",
        "landmarks = np.matrix([[p.x, p.y] for p in detected_landmarks])\n",
        "\n",
        "landmarks_display = landmarks[RIGHT_EYE_POINTS + LEFT_EYE_POINTS + MOUTH_OUTLINE_POINTS]   \n",
        "\n",
        "   # copying the image so we can see side-by-side  \n",
        "image_copy = image.copy()  \n",
        "   \n",
        "for idx, point in enumerate(landmarks_display):  \n",
        "    pos = (point[0, 0], point[0, 1])  \n",
        "   \n",
        "     # annotate the positions  \n",
        "    cv2.putText(image_copy, str(idx), pos,  \n",
        "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,  \n",
        "        fontScale=0.4,  \n",
        "        color=(0, 0, 255))  \n",
        "   \n",
        "     # draw points on the landmark positions  \n",
        "    cv2.circle(image_copy, pos, 3, color=(0, 255, 255))  \n",
        "   \n",
        "cv2.imshow(\"Faces found\", image)  \n",
        "cv2.imshow(\"Landmarks found\", image_copy)  \n",
        "cv2.waitKey(0)  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}